# Helper functions ----

#' Checks the reference types in a file are valid Data Store reference types
#'
#' Reads in a .txt file for data validation. Checks the values supplied in the column reference_type using the DataStore API to determine whether they are valid reference types, as stored in the DataStore backend. Note that the Reference Type listed on the DataStore web page (e.g. Audio Recording) is NOT the correct, valid reference type. In this case the valid reference type would be AudioRecording. If any reference type is invalid, the function throws an error and prints a list of the invalid reference types. If all reference types are valid, the function passes.
#'
#' @param filename String. Input file to check. Defaults to "DSbulkdUploadR_input.xlsx"
#' @param path String. Path to the file. Defaults to the current working directory.
#' @param sheet_name String. Name of the excel sheet to check.
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_ref_type("test_file.txt")}
check_ref_type <- function(path = getwd(),
                           filename = "DSbulkUploadR_input.xlsx",
                           sheet_name) {

  #upload_data <- read.delim(file=paste0(path, "/", filename))
  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  refs <- upload_data$reference_type

  url <- paste0(.ds_secure_api(), "FixedList/ReferenceTypes")
  #API call to look for an existing reference:
  req <- httr::GET(url, httr::authenticate(":", ":", "ntlm"))
  status_code <- httr::stop_for_status(req)$status_code

  #if API call fails, alert user and remind them to log on to VPN:
  if(!status_code == 200){
    stop("DataStore connection failed.")
  }

  refs_json <- httr::content(req, "text")
  refs_rjson <- jsonlite::fromJSON(refs_json)

  refs <- unique(refs)
  bad_refs <- refs[!(refs %in% refs_rjson$key)]

  if (length(bad_refs > 0)) {
    msg <- paste0("Please use valid reference types. The following ",
                  "reference types are invalid: {bad_refs}.")
    cli::cli_abort(c("x" = msg))
  }
  cli::cli_inform(c("v" = "All reference types are valid."))
  return(invisible(NULL))
}

#' Check that Reference Types are Supported
#'
#' Runs a check against a hardcoded list of currently supporte DataStore reference types. If an unsupported reference type is supplied, the function will fail with an error and the error message will return the specific reference type(s) that are unsupported. If the reference types are all supported, the function will pass.  See the \href{https://nationalparkservice.github.io/DSbulkUploadR/articles/02_Generate-the-Input-File.html#create-an-input-template}{package documentation} for a list of currently supported references and information on using them.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_ref_type_supported(filename = "test_file.txt")}
check_ref_type_supported <- function(path = getwd(),
                                     filename = "DSbulkUploadR_input.xlsx",
                                     sheet_name) {

  #upload_data <- read.delim(file=paste0(path, "/", filename))
  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  refs <- upload_data$reference_type

  # hardcoded list of supported refs. Will need manual updates
  supported_refs <- c("AudioRecording",
                      "GenericDocument",
                      "WebSite")

  bad_refs <- refs[(!refs %in% supported_refs)]
  bad_refs <- unique(bad_refs)

  if (length(bad_refs > 0)) {
    msg <- paste0("The following reference types are unsupported: ",
                  "{bad_refs}. Please supply only currently supported ",
                  "reference types.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All reference types supplied are supported.")
    cli::cli_inform(c("v" = msg))
  }
}

#' Checks that each file_path in a file contains files
#'
#' Reads in a .txt file for data validation. For each item in the column file_path, the function checks whether the path given contains file. If the path given does not contain files (or is not a valid path), the function will throw an error and list the bad paths. If all paths contain valid files, the function passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_files_exist("test_file.txt")
#' }
check_files_exist <- function(path = getwd(),
                              filename = "DSbulkUploadR_input.xlsx",
                              sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  bad_files <- NULL
  for (i in 1:nrow(upload_data)) {
    if (!file.exists(path = upload_data$file_path[i])) {
      bad_files <- append(bad_files, upload_data$title[i])
    }
  }
  if (!is.null(bad_files)) {
    msg <- paste0("All references must have files to upload. ",
                  "The following references have a bad file path ",
                  "or no files associated with them:\n {bad_files}")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All file paths contain file for upload.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Checks whether the total number of file to upload exceeds a threshold
#'
#' Reads in a .txt file for data validation. Checks the number of files located in each directory supplied via the column file_path. If the total number of files exceeds the file_number_error value, the function produces an error. If the total number of files exceeds 50% of the file_number_error value the function produces a warning. Otherwise the function passes.
#'
#' @inheritParams check_ref_type
#' @param file_number_error Integer. Maximum allowable number of files. Defaults to 500.
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_file_number("test_file.txt")
#' }
check_file_number <- function(filename = "DSbulkUploadR_input.xlsx",
                              path = getwd(),
                              sheet_name,
                              file_number_error = 500) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)

  file_num <- 0
  for (i in 1:nrow(upload_data)) {
    files_per_ref <- length(list.files(upload_data$file_path[i]))
    file_num <- (file_num + files_per_ref)
  }
  if (file_num > file_number_error) {
    msg <- paste0("You are attempting to upload {file_num} files, ",
                  "which exceeds the maximum allowable number, ",
                  "({file_number_error} files). Please either adjust ",
                  "the maximum number of files or attempt to upload ",
                  "fewer files.")
    cli::cli_abort(c("x" = msg))
  } else if (file_num > (file_number_error * 0.5)) {
    msg <- paste0("You are attempting to upload {file_num} files, ",
                  "which has triggered a warning. Please make sure you ",
                  "want to upload this many files.")
    cli::cli_warn(c("!" = msg))
  } else {
    msg <- paste0("The files to upload does not exceed the maximum number.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Checks whether the total file size to upload exceeds some threshold
#'
#'  Reads in a .txt file for data validation. Checks the file size of files located in each directory supplied via the column file_path. If the total file size exceeds the file_size_error value, the function produces an error. If the total number of files exceeds 50% of the file_number_error value the function produces a warning. Otherwise the function passes.
#'
#' @inheritParams check_ref_type
#' @param file_size_error Integer. The maximum allowable total file size in GB. Defaults to 100 GB.
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_file_size("test_file.txt")
#' }
check_file_size <- function(filename = "DSbulkUploadR_input.xlsx",
                            path = getwd(),
                            sheet_name,
                            file_size_error = 100) {
  #convert gb to bytes:
  error_bytes <- file_size_error * 1073741824
  warn_bytes <- error_bytes * 0.5
  #get input data to validate:
  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  file_size <- 0
  for (i in 1:nrow(upload_data)) {
    file_size <- file_size +
      sum(file.info(list.files(upload_data$file_path[i],
                               full.names = TRUE))$size)
  }
  file_gb <- file_size/1073741824
  if (file_size > error_bytes) {
    msg <- paste0("You are attempting to upload {file_gb} GB of data, ",
                  "which exceeds the maximum allowable number, ",
                  "({file_size_error} GB) per bulk upload. Please either ",
                  "adjust the maximum data upload amount, or attempt to ",
                  "upload less data.")
    cli::cli_abort(c("x" = msg))
  } else if (file_size > warn_bytes) {
    msg <- paste0("You are attempting to upload {file_gb} GB of data, ",
                  "which has triggered a warning. Please make sure you ",
                  "want to upload this much data.")
    cli::cli_inform(c("!" = msg))
  } else
    msg <- paste0("The cumulative file size to upload does ",
                  "not exeed the maximum allowable.")
  cli::cli_inform(c("v" = msg))
  return(invisible(NULL))
}

#' Checks a column within a supplied file to ascertain whether 508 status has been supplied.
#'
#' Reads in a .txt file for data validation. Checks the column files_508_compliant to make sure that all values are either 'yes' or 'no', which indicates the 508 compliant status of any associated files to be uploaded to DataStore. If any values are missing or are not 'yes' or 'no' (where case is ignored), the function throws an error. If all values have either a 'yes' or 'no' value associated with them, the function passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_508_format("test_file.txt")}
check_508_format <- function(path = getwd(),
                             filename = "DSbulkUploadR_input.xlsx",
                             sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)

  is_508 <- tolower(upload_data$files_508_compliant) != "yes" &
    tolower(upload_data$files_508_compliant) != "no"
  if (sum(is_508) > 0) {
    msg <- paste0('All files must have a 508 compiance status of "yes" ',
                  'or "no". Please provide valid 508 compliance for ',
                  'each reference.')
    cli::cli_abort(c("x" = msg))
  } else {
    cli::cli_inform(
      c("v" = "All files have a valid 508 compliance designation"))
  }
  return(invisible(NULL))
}

#' Checks for duplicated reference titles
#'
#' Reads in a .txt file for data validation. Checks the column title to make sure all values are unique. If any values are duplicated, the function throws an error and returns a list of the duplicated values. If all the values are unique, the function passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_unique_title("test_file.txt")}
check_unique_title <- function(path = getwd(),
                              filename = "DSbulkUploadR_input.xlsx",
                              sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  duplicates <- duplicated(upload_data$title)
  if (any(duplicates)) {
    msg <- paste0("All reference titles must be unique. The following titles ",
                  "are duplicated: {upload_data$title[duplicates]}.")
    cli::cli_abort(c("x" = msg))
  } else {
    cli::cli_inform(c("v" = "All reference titles are unique"))
  }
  return(invisible(NULL))
}

#' Checks the begin_content_date column of an input file for ISO 8601 formatting
#'
#' Reads in a .txt file for data validation. Throws an error if any dates in the content_begin_date column are not in ISO 8601 (yyyy-mm-dd). Passes if all dates in the content_begin_date column are in ISO 8601 format.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_start_date <- ("test_file.txt")}
check_start_date <- function(path = getwd(),
                            filename = "DSbulkUploadR_input.xlsx",
                            sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  start_dates <- upload_data$content_begin_date
  #valid dates are "TRUE"
  valid_dates <- !is.na(suppressWarnings(lubridate::ymd(start_dates)))
  if (sum(valid_dates) < nrow(upload_data)) {
    msg <- paste0("Some content begin dates are not in ISO 8601 format ",
                  "(yyyy-mm-dd). Please supply all dates in ISO 8601 format.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All content begin dates are supplied ",
                  "in the correct format.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Checks the end_content_date column of an input file for ISO 8601 formatting
#'
#' Reads in a .txt file for data validation. Throws an error if any dates in the content_end_date column are not in ISO 8601 (yyyy-mm-dd). Passes if all dates in the content_begin_date column are in ISO 8601 format.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_end_date("test_file.txt")
#' }
check_end_date <- function(path = getwd(),
                          filename = "DSbulkUploadR_input.xlsx",
                          sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  end_dates <- upload_data$content_end_date
  valid_dates <- !is.na(suppressWarnings(lubridate::ymd(end_dates)))
  if (sum(valid_dates) < nrow(upload_data)) {
    msg <- paste0("Some content end dates are not in ISO 8601 format ",
                  "(yyyy-mm-dd). Please supply all dates in ISO 8601 format.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All content end dates are supplied ",
                  "in the correct format.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Checks that content_end_dates occur after content_begin_dates in a file.
#'
#' Reads in a .txt file for data validation. Throws an error if any dates in the content_end_date column occur before the date in the same row for the content_begin_date column. Passes if all end dates occur on or after the being date.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_end_after_start("test_file.txt")
#' }
check_end_after_start <- function(path = getwd(),
                                  filename = "DSbulkUploadR_input.xlsx",
                                  sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  end_dates <- lubridate::ymd(upload_data$content_end_date)
  start_dates <- lubridate::ymd(upload_data$content_begin_date)
  time_dif <- lubridate::interval(start_dates, end_dates)
  if (any(time_dif < 0)) {
    msg <- paste0("Some content end dates predate content start dates. ",
                  "Please make sure end dates are after start dates.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All end dates occur after start dates.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Checks that dates in a file occurred in the past.
#'
#' Reads in a .txt file for data validation. Throws an error if dates in either the content_begin_date or content_end_date occur after the current system date. If any dates occur in the future the function results in an error. The test passes if all dates occur in the past (or on the present day).
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_dates_past("test_file.txt")
#' }
check_dates_past <- function(path = getwd(),
                            filename = "DSbulkUploadR_input.xlsx",
                            sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  end_dates <- lubridate::ymd(upload_data$content_end_date)
  start_dates <- lubridate::ymd(upload_data$content_begin_date)
  today <- Sys.Date()

  check_start <- lubridate::interval(start_dates, today)
  check_end <- lubridate::interval(end_dates, today)

  if (any(check_start < 0) | any(check_end < 0)) {
    msg <- paste0("Some of your content start or end dates occur in the ",
                  "future. Please make sure all dates occur in the past.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All content start and end dates occur in the past.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Verifies author emails supplied in file.
#'
#' Reads in a .txt file for data validation. Checks that all author emails supplied in the column author_emails are valid NPS emails. Each instance of author emails contain a single email or a comma separated list of emails (e.g. just joe.smith@nps.gov or joe.smith@nps.gov, jane.doe@partner.nps.gov). If any email is not a valid NPS email, the function will throw an error and list the invalid emails (check for typos!). If all emails supplied are valid NPS emails, the function will pass. This function uses an API rather than Active Directory to access lists of valid NPS emails.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_author_email("test_file.txt")}
check_author_email <- function(path = getwd(),
                              filename = "DSbulkUploadR_input.xlsx",
                              sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  #skip test for WebSite reference type which does not have authors
  if (any(upload_data$reference_type == "WebSite")) {
    msg <- "Refernce type WebSite does not require authors"
    cli::cli_inform(c("v" = msg))
    return(invisible(NULL))
  }

  usr_email <- NULL
  for (i in 1:nrow(upload_data)) {
    usr_email <-
      append(usr_email,
             unlist(stringr::str_split(upload_data$author_email_list[i], ",")))
  }
  usr_email <- stringr::str_trim(usr_email)
  usr_email <- unique(usr_email)
  req_url <- paste0("https://irmadevservices.nps.gov/",
                    "adverification/v1/rest/lookup/email")
  bdy <- usr_email
  req <- httr::POST(req_url,
                    httr::add_headers('Content-Type' = 'application/json'),
                    body = rjson::toJSON(bdy))
  status_code <- httr::stop_for_status(req)$status_code
  if (!status_code == 200) {
    cli::cli_abort(c("x" = "ERROR: Active Directory connection failed."))
  }
  json <- httr::content(req, "text")
  rjson <- jsonlite::fromJSON(json)

  if (all(rjson$found)) {
    cli::cli_inform(c("v" = "All author emails are valid."))
  } else {
    bad_usr_emails <- dplyr::filter(rjson, found==FALSE)$searchTerm
    msg <- paste0("Please supply valid emails. The following emails ",
                  "are invalid: {bad_usr_emails}.")
    cli::cli_abort(c("x" = msg))
  }
  return(invisible(NULL))
}

#checks to make sure all users have orcids and that orcids are correctly formatted. Does not check whether orcids are valid/associated with the correct username.
#' Checks to make sure all author email accounts have ORCiDs
#'
#' Reads in a .txt file for data validation. Checks all the emails listed in the column author_emails and verifies whether these emails have ORCiDs associated with the via an NPS API. If any user account associated with an email does not have an ORCiD associated with it (including all emails that are not valid NPS emails), the function throws an error and lists the emails that do not have ORCiDs associated with them. If all emails are tied to valid NPS accounts with ORCiDs associated with them, the function passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_authors_orcid("test_file.txt")}
check_authors_orcid <- function(path = getwd(),
                               filename = "DSbulkUploadR_input.xlsx",
                               sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)

  #skip test for WebSite reference type which does not have authors
  if (any(upload_data$reference_type == "WebSite")) {
    msg <- "Refernce type WebSite does not require authors"
    cli::cli_inform(c("v" = msg))
    return(invisible(NULL))
  }

  usr_email <- NULL
  for (i in 1:nrow(upload_data)) {
    usr_email <-
      append(usr_email,
             unlist(stringr::str_split(upload_data$author_email_list[i], ",")))
  }
  usr_email <- stringr::str_trim(usr_email)
  usr_email <- unique(usr_email)
  req_url <- paste0("https://irmadevservices.nps.gov/",
                    "adverification/v1/rest/lookup/email")
  bdy <- usr_email
  req <- httr::POST(req_url,
                    httr::add_headers('Content-Type' = 'application/json'),
                    body = rjson::toJSON(bdy))
  status_code <- httr::stop_for_status(req)$status_code
  if (!status_code == 200) {
    stop("ERROR: DataStore connection failed.")
  }
  json <- httr::content(req, "text")
  rjson <- jsonlite::fromJSON(json)

  # test whether orcids exist in active directory:
  if(sum(is.na(rjson$extensionAttribute2)) == 0) {
    cli::cli_inform(c("v" = "All users have ORCiDs."))
  } else {
    no_orcid <- dplyr::filter(rjson, is.na(rjson$extensionAttribute2))$searchTerm
    msg <- paste0("All authors must have ORCiDs. Please have the ",
                  "following authors add ORCiDs to Active Directory ",
                  "prior to proceeding with reference creation: {no_orcid}.")
    cli::cli_abort(c("x" = msg))
  }
  return(invisible(NULL))
}

#' Checks the formatting of ORCiDs associated with NPS emails supplied in a file
#'
#' Reads in a .txt file for data validation. Uses an NPS API to check that all the emails listed in the column author_emails have properly formatted ORCiDs (xxxx-xxxx-xxx-xxxx) associated with them. Lack of an ORCiD, including because the supplied email address is not a valid NPS email, is considered improperly formatted for the purposes of this test. emails supplied do not have properly formatted ORCiDs associated with them the function throws an error and lists the emails that do not have properly formatted ORCiDs associated with them. If all emails are tied to valid NPS accounts with properly formatted ORCiDs associated with them, the function passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_orcid_format("test_file.txt")}
check_orcid_format <- function(path = getwd(),
                              filename = "DSbulkUploadR_input.xlsx",
                              sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)

  #skip test for WebSite reference type which does not have authors
  if (any(upload_data$reference_type == "WebSite")) {
    msg <- "Refernce type WebSite does not require authors"
    cli::cli_inform(c("v" = msg))
    return(invisible(NULL))
  }

  usr_email <- NULL
  for (i in 1:nrow(upload_data)) {
    usr_email <-
      append(usr_email,
             unlist(stringr::str_split(upload_data$author_email_list[i], ",")))
  }
  usr_email <- stringr::str_trim(usr_email)
  usr_email <- unique(usr_email)
  req_url <- paste0("https://irmadevservices.nps.gov/",
                    "adverification/v1/rest/lookup/email")
  bdy <- usr_email
  req <- httr::POST(req_url,
                    httr::add_headers('Content-Type' = 'application/json'),
                    body = rjson::toJSON(bdy))
  status_code <- httr::stop_for_status(req)$status_code
  if (!status_code == 200) {
    stop("ERROR: DataStore connection failed.")
  }
  json <- httr::content(req, "text")
  rjson <- jsonlite::fromJSON(json)
  # test whether orcids are valid:
  rjson$orcid_format <- grepl('[0-9]{4}-[0-9]{4}-[0-9]{4}-[0-9]{3}[A-Za-z0-9]{1}', rjson$extensionAttribute2)
  if (sum(rjson$orcid_format) == nrow(rjson)) {
    cli::cli_inform(c("v" = "All ORCiDs have a valid format"))
  } else {
    rjson2 <- rjson %>% dplyr::filter(rjson$orcid_format == FALSE)
    msg <- paste0("All authors must have ORCiDs with valid formats. ",
                  "The following authors have ORCiDs with invalid formats ",
                  "(which may include lack of any ORCiD) listed in Active ",
                  "Dirctory: {rjson2$searchTerm}.")
    cli::cli_abort(c("x" = msg))
  }
  return(invisible(NULL))
}

#' check_author_email("test_file.txt")}
check_owner_email <- function(path = getwd(),
                               filename = "DSbulkUploadR_input.xlsx",
                               sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)

  owner_email <- NULL
  for (i in 1:nrow(upload_data)) {
    owner_email <-
      append(owner_email,
             unlist(stringr::str_split(upload_data$owner_email_list[i], ",")))
  }
  owner_email <- stringr::str_trim(owner_email)
  owner_email <- unique(owner_email)
  req_url <- paste0("https://irmadevservices.nps.gov/",
                    "adverification/v1/rest/lookup/email")
  bdy <- owner_email
  req <- httr::POST(req_url,
                    httr::add_headers('Content-Type' = 'application/json'),
                    body = rjson::toJSON(bdy))
  status_code <- httr::stop_for_status(req)$status_code
  if (!status_code == 200) {
    cli::cli_abort(c("x" = "ERROR: Active Directory connection failed."))
  }
  json <- httr::content(req, "text")
  rjson <- jsonlite::fromJSON(json)

  if (all(rjson$found)) {
    cli::cli_inform(c("v" = "All owner emails are valid."))
  } else {
    bad_owner_emails <- dplyr::filter(rjson, found==FALSE)$searchTerm
    msg <- paste0("Please supply valid emails. The following emails ",
                  "are invalid: {bad_owner_emails}.")
    cli::cli_abort(c("x" = msg))
  }
  return(invisible(NULL))
}

#' Checks an file for valid license types
#'
#' Reads in a .txt file for data validation. Checks all values supplied in the license_code column for valid DataStore license codes. Valid codes are as follows: 1) "Creative Commons Zero v1.0 Universal (CC0)". This is the preferred license for all public content. 2) "Creative Commons Attribution 4.0 International", 3) "Creative commons Attribution Non Commercial 4.0 International" (This license may be useful when working with partners external to NPS), 4) "Public Domain", 5) "Unlicensed (not for public dissemination)" (should only be used for restricted content that contains confidential unclassified information - CUI). If all license codes supplied (as integers ranging from 1-5) are valid, the function passes. If any license code is missing or invalid, the function throws an error.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_license_type("test_file.txt")}
check_license_type <- function(path = getwd(),
                               filename = "DSbulkUploadR_input.xlsx",
                               sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  if (any(is.na(upload_data$license_code))) {
    msg <- paste0("You must supply a license type for all references.")
    cli::cli_abort(c("x" = msg))
  }
  valid_license <- sum(upload_data$license_code != (1 | 2 |3 | 4 | 5))
  if (valid_license > 0) {
    msg <- paste0("You have supplied an invalid license code. ",
                  "Please supply a valid license code.")
    cli::cli_abort(c("x" = msg))
  } else {
    cli::cli_inform(c("v" = "All license codes are valid."))
  }
  return(invisible(NULL))
}

#' Checks for valid producing unit codes in a file
#'
#' Reads in a .txt file for data validation. Uses the NPS Unit Service API to check that the producing_units column contains valid NPS unit codes. If invalid producing units are encountered, the function throws an error and prints a list of the invalid units to the console. If all units are valid, the test passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_units("test_file.txt")
#' }
check_prod_units <- function(path = getwd(),
                            filename = "DSbulkUploadR_input.xlsx",
                            sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)
  #get list of all units:
  f <- file.path(tempdir(), "irmadownload.xml")
  if (!file.exists(f)) {
    # access all park codes from NPS xml file
    curl::curl_download("https://irmaservices.nps.gov/Unit/v2/api/", f)
  }
  result <- XML::xmlParse(file = f)
  dat <- XML::xmlToDataFrame(result)

  #check for bad producing units:
  producing_units <- NULL
  for (i in 1:nrow(upload_data)) {
    producing_units <-
      append(producing_units,
             unlist(stringr::str_split(upload_data$producing_units[i], ", ")))
  }
  producing_units <- unique(producing_units)
  bad_prod_units <- producing_units[!(producing_units %in% dat$UnitCode)]

  if (length(bad_prod_units > 0)) {
    msg <- paste0("The following producing units are invalid. ",
                  "Please provide valid producing units: {bad_prod_units}.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All producing units are valid.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#' Checks for valid content unit codes in a file
#'
#' Reads in a .txt file for data validation. Uses the NPS Unit Service API to check that the content_units column contains valid NPS unit codes. If invalid content units are encountered, the function throws an error and prints a list of the invalid units to the console. If all units are valid, the test passes.
#'
#' @inheritParams check_ref_type
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_content_units("test_file.txt")}
check_content_units <- function(path = getwd(),
                               filename = "DSbulkUploadR_input.xlsx",
                               sheet_name) {

  upload_data <- readxl::read_excel(path = paste0(path,
                                                  "/",
                                                  filename),
                                    sheet = sheet_name)

  #get list of all units:
  f <- file.path(tempdir(), "irmadownload.xml")
  if (!file.exists(f)) {
    # access all park codes from NPS xml file
    curl::curl_download("https://irmaservices.nps.gov/Unit/v2/api/", f)
  }
  result <- XML::xmlParse(file = f)
  dat <- XML::xmlToDataFrame(result)

  #check for bad conten units:
  content_units <- NULL
  for (i in 1:nrow(upload_data)) {
    content_units <-
      append(content_units,
             unlist(stringr::str_split(upload_data$content_units[i], ", ")))
  }
  content_units <- unique(content_units)
  bad_content_units <- content_units[!(content_units %in% dat$UnitCode)]

  if (length(bad_content_units > 0)) {
    msg <- paste0("Please provide valid content units. The following ",
                  "content units are invalid: {bad_content_units}.")
    cli::cli_abort(c("x" = msg))
  } else {
    msg <- paste0("All content units are valid.")
    cli::cli_inform(c("v" = msg))
  }
  return(invisible(NULL))
}

#uses AD to verify users upn. Will not work after transition to entraID.
#' Checks whether a upn supplied is valid.
#'
#' `r lifecycle::badge("deprecated")`
#'
#' Reads in a .txt file for data validation. Checks all user names supplied in the column author_upn against Active Directory using a powershell script to verify that the accounts are valid NPS accounts. The function throws an error and lists any invalid accounts if they are encountered. Additionally, if all accounts are valid the function throws and error if any accounts do not have ORCiDs associated with them (and lists those accounts). If all accounts are valid and have ORCiDs, the function passes.
#'
#' @param filename String. File to check.
#' @param path String. Path to file. Defaults to the current working directory.
#'
#' @returns NULL (invisibly)
#' @export
#'
#' @examples
#' \dontrun{
#' check_users_AD("test_file.txt")}
check_users_AD <- function(filename, path = getwd()){
  lifecycle::deprecate_warn("0.0.1",
                            "check_users_AD()",
                            "check_author_email()")

  upload_data <- read.delim(file=paste0(path, "/", filename))
  #check for bad usernames:
  usr_name <- NULL
  for (i in 1:nrow(upload_data)) {
    usr_name <-
      append(usr_name,
             unlist(stringr::str_split(upload_data$author_upn_list[i], ", ")))
  }
  usr_name <- unique(usr_name)

  bad_usr <- NULL
  invalid_orcid <- NULL
  for (i in 1:length(usr_name)) {
    powershell_command <- paste0('([adsisearcher]\\"(samaccountname=',
                                 usr_name[i],
                                 ')\\").FindAll().Properties')

    AD_output <- system2("powershell",
                         args = c("-Command",
                                  powershell_command),
                         stdout = TRUE)

    if (length(AD_output) == 0 ) {
      bad_usr <- append(bad_usr, usr_name)
    }
    #check_orcid - doesn't check formatting just presence/absence and nchar.
    orcid <- AD_output[
      which(AD_output %>% stringr::str_detect("extensionattribute2\\b"))]
    #get orcid from output
    orcid <- stringr::str_extract(orcid, "\\{.*?\\}")
    # remove curly braces:
    orcid <- stringr::str_remove_all(orcid, "[{}]")
    if (length(orcid == 0)) {
      invalid_orcid <- append(invalid_orcid, usr_name)
    }
    if (!grep('[0-9]{4}-[0-9]{4}-[0-9]{4}-[0-9]{3}[A-Za-z0-9]{1}', orcid)) {
      invalid_orcid <- append(invalid_orcid, usr_name)
    }
  }
  if (!is.null(bad_usr)) {
    msg <- paste0("The following usernames are invalid. Please provide ",
                  "valid usernames: {bad_usr}.")
    cli::cli_abort(c("x" = msg))
  }
  if (!is.null(invalid_orcid)) {
    msg <- paste0("The following usernames do not have ORCIDs (or have ",
                  "invalid ORCIDs) associated with them. Please have the ",
                  "users add valid ORCIDs (https://orcid.org) to their ",
                  "Active Directory account at https://myaccount.nps.gov/: ",
                  "{invalid_orcid}.")
    cli::cli_abort(c("x" = msg))
  }
  msg <- "All users have NPS accounts and valid ORCiDs associated with them."
  cli::cli_inform(c("v" = msg))
  return(invisible(NULL))
}
